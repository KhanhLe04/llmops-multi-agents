# ğŸ“š Data Preparing - Há»‡ Thá»‘ng Xá»­ LÃ½ Dá»¯ Liá»‡u Mental Health RAG

## ğŸ¯ Tá»•ng Quan

Module `data-preparing` lÃ  thÃ nh pháº§n cá»‘t lÃµi cá»§a há»‡ thá»‘ng LLMOps Multi-Agent, chuyÃªn xá»­ lÃ½ vÃ  chuáº©n bá»‹ dá»¯ liá»‡u cho domain **tÆ° váº¥n sá»©c khá»e tÃ¢m lÃ½ há»c sinh sinh viÃªn**. Module nÃ y thá»±c hiá»‡n toÃ n bá»™ pipeline tá»« viá»‡c xá»­ lÃ½ tÃ i liá»‡u PDF gá»‘c Ä‘áº¿n viá»‡c lÆ°u trá»¯ embeddings trong vector database.

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
data-preparing/
â”œâ”€â”€ ğŸ“„ config.py              # Cáº¥u hÃ¬nh toÃ n bá»™ há»‡ thá»‘ng
â”œâ”€â”€ ğŸš€ ingest_data.py          # Pipeline chÃ­nh xá»­ lÃ½ dá»¯ liá»‡u
â”œâ”€â”€ ğŸ“Š pyproject.toml          # Dependencies vÃ  metadata
â”œâ”€â”€ ğŸ› ï¸  utils/                 # CÃ¡c module tiá»‡n Ã­ch
â”‚   â”œâ”€â”€ pdf_processor.py       # Xá»­ lÃ½ PDF vÃ  chunking
â”‚   â”œâ”€â”€ embedding_manager.py   # Quáº£n lÃ½ embedding models
â”‚   â””â”€â”€ qdrant_manager.py      # Quáº£n lÃ½ vector database
â”œâ”€â”€ ğŸ§ª benchmarks/             # ÄÃ¡nh giÃ¡ embedding models
â”‚   â””â”€â”€ embedding/
â”‚       â”œâ”€â”€ hit_at_k_benchmark.py      # Benchmark retrieval
â”‚       â”œâ”€â”€ sts_correlation_benchmark.py # Benchmark semantic similarity
â”‚       â””â”€â”€ results/                   # Káº¿t quáº£ benchmark
â””â”€â”€ ğŸ“ data/                   # ThÆ° má»¥c chá»©a PDF nguá»“n
```

## âš™ï¸ Cáº¥u HÃ¬nh Há»‡ Thá»‘ng (`config.py`)

### ğŸ”§ Cáº¥u HÃ¬nh CÆ¡ Báº£n

```python
class Config:
    # Vector Database
    QDRANT_URL = "http://localhost:6333"
    COLLECTION_NAME = "mental_health_advisor"
    
    # Embedding Model - Tá»‘i Æ°u cho tiáº¿ng Viá»‡t
    EMBEDDING_MODEL = "intfloat/multilingual-e5-base"
    
    # Chunking Strategy - Tá»‘i Æ°u cho ná»™i dung tÃ¢m lÃ½
    CHUNK_SIZE = 800           # KÃ­ch thÆ°á»›c chunk phÃ¹ há»£p
    CHUNK_OVERLAP = 150        # Overlap Ä‘á»ƒ báº£o toÃ n ngá»¯ cáº£nh
    
    # Retrieval Settings
    TOP_K_DOCUMENTS = 3        # Sá»‘ document tráº£ vá»
    SIMILARITY_THRESHOLD = 0.65 # NgÆ°á»¡ng Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
```

### ğŸ›ï¸ TÃ¹y Chá»n NÃ¢ng Cao

- **CHUNK_STRATEGY**: `"recursive"` - Chiáº¿n lÆ°á»£c chia chunk thÃ´ng minh
- **OVERLAP_METHOD**: `"sentence"` - Overlap theo ranh giá»›i cÃ¢u
- **NORMALIZE_EMBEDDINGS**: Chuáº©n hÃ³a vector embeddings
- **EMBEDDING_BATCH_SIZE**: KÃ­ch thÆ°á»›c batch cho embedding (tá»‘i Æ°u cho Vietnamese models)

## ğŸ”„ Pipeline Xá»­ LÃ½ Dá»¯ Liá»‡u (`ingest_data.py`)

### ğŸ“‹ Quy TrÃ¬nh ChÃ­nh

```python
class MentalHealthDataIngestion:
    def __init__(self):
        self.pdf_processor = PDFProcessor()
        self.embedding_manager = EmbeddingManager()
        self.qdrant_manager = QdrantManager()
```

### ğŸš€ CÃ¡c BÆ°á»›c Thá»±c Hiá»‡n

1. **ğŸ“– PhÃ¢n TÃ­ch PDF** (`analyze_pdf_content`)
   - Kiá»ƒm tra kháº£ nÄƒng Ä‘á»c file
   - ÄÃ¡nh giÃ¡ Ä‘á»™ dÃ i ná»™i dung
   - Validation cÆ¡ báº£n

2. **ğŸ”„ Xá»­ LÃ½ PDF** (`process_pdfs`)
   - TrÃ­ch xuáº¥t text tá»« PDF
   - Chia thÃ nh chunks thÃ´ng minh
   - Táº¡o metadata Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£

3. **ğŸ’¾ LÆ°u Trá»¯ Vector DB** (`store_in_vector_db`)
   - Táº¡o embeddings cho tá»«ng chunk
   - LÆ°u vÃ o Qdrant vá»›i metadata
   - Thá»‘ng kÃª vÃ  bÃ¡o cÃ¡o

### ğŸ“Š Metadata Structure (ÄÃ£ Tá»‘i Æ¯u)

```python
{
    "content": "Ná»™i dung chunk",
    "source": "tÃªn_file.pdf",
    "chunk_index": 0,
    "doc_id": "uuid-generated-id",
    "section": "ChÆ°Æ¡ng 1: Giá»›i thiá»‡u"
}
```

**âœ… Loáº¡i bá» cÃ¡c metadata thá»«a**: `content_type`, `char_count`, `word_count`, `chunk_id`, `total_chunks`, `domain`, `contains_crisis_keywords`, `contains_student_keywords`, `priority_level`, `tags`

## ğŸ“„ PDF Processor (`utils/pdf_processor.py`)

### ğŸ¯ TÃ­nh NÄƒng ChÃ­nh

#### ğŸ“– TrÃ­ch Xuáº¥t Text
- **Encoding UTF-8**: Xá»­ lÃ½ hoÃ n háº£o tiáº¿ng Viá»‡t
- **Page Markers**: ThÃªm `---PAGE_x---` Ä‘á»ƒ theo dÃµi trang
- **Error Handling**: Xá»­ lÃ½ robust cÃ¡c lá»—i PDF

#### âœ‚ï¸ Chunking ThÃ´ng Minh
```python
separators = [
    "\n\n\n",  # Section breaks
    "\n\n",    # Paragraph breaks  
    "\n",      # Line breaks
    ". ",      # Sentence ends
    "! ",      # Exclamation
    "? ",      # Question
    "; ",      # Semicolon
    ", ",      # Comma
    " "        # Space
]
```

#### ğŸ§¹ Text Cleaning
- **Vietnamese Text Normalization**: Chuáº©n hÃ³a kÃ½ tá»± tiáº¿ng Viá»‡t
- **Page Number Separation**: TÃ¡ch sá»‘ trang khá»i ná»™i dung chÃ­nh
- **Section Extraction**: TrÃ­ch xuáº¥t tiÃªu Ä‘á» section tá»± Ä‘á»™ng

#### ğŸ·ï¸ Metadata Generation
```python
def create_chunks(self, documents: List[Document]) -> List[Dict]:
    doc_id = str(uuid.uuid4())  # Unique document ID
    
    for chunk in chunks:
        content, page_info = self.separate_page_numbers(chunk.page_content)
        section = self.extract_section_from_content(content)
        
        chunk_dict = {
            "content": content,
            "source": source_name,
            "chunk_index": chunk_index,
            "doc_id": doc_id,
            "section": section
        }
```

## ğŸ§® Embedding Manager (`utils/embedding_manager.py`)

### ğŸ¯ TÃ­nh NÄƒng ChÃ­nh

#### ğŸ¤– Model Loading vá»›i Error Handling
```python
try:
    self.model = SentenceTransformer(Config.EMBEDDING_MODEL)
except ValueError as ve:
    if "trust_remote_code" in str(ve):
        # Auto-retry vá»›i trust_remote_code=True
        self.model = SentenceTransformer(
            Config.EMBEDDING_MODEL, 
            trust_remote_code=True
        )
```

#### ğŸ”„ Batch Processing
- **Progressive Batch Size Reduction**: Tá»± Ä‘á»™ng giáº£m batch size khi gáº·p lá»—i
- **Memory Management**: Tá»‘i Æ°u sá»­ dá»¥ng GPU/CPU memory
- **Error Recovery**: Xá»­ lÃ½ robust cÃ¡c lá»—i encoding

#### ğŸ“Š Text Preprocessing
```python
def preprocess_text(self, text: str) -> str:
    # Loáº¡i bá» control characters
    text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)
    
    # Normalize whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Truncate táº¡i sentence boundary
    if len(text) > self.max_length:
        text = self.truncate_at_sentence_boundary(text)
    
    return text
```

## ğŸ—„ï¸ Qdrant Manager (`utils/qdrant_manager.py`)

### ğŸ¯ TÃ­nh NÄƒng ChÃ­nh

#### ğŸ”— Connection Management
- **Health Check**: Kiá»ƒm tra káº¿t ná»‘i vÃ  collection status
- **Auto Collection Creation**: Tá»± Ä‘á»™ng táº¡o collection náº¿u chÆ°a tá»“n táº¡i
- **Error Handling**: Xá»­ lÃ½ robust cÃ¡c lá»—i káº¿t ná»‘i

#### ğŸ’¾ Document Storage
```python
def add_documents(self, chunks: List[Dict], embeddings: List[List[float]]):
    points = []
    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
        payload = {
            "content": chunk["content"],
            "source": chunk["source"], 
            "chunk_index": chunk["chunk_index"],
            "doc_id": chunk["doc_id"],
            "section": chunk["section"]
        }
        
        point = PointStruct(
            id=str(uuid.uuid4()),
            vector=embedding,
            payload=payload
        )
        points.append(point)
```

#### ğŸ” Search Capabilities
- **Semantic Search**: TÃ¬m kiáº¿m dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vector
- **Filtered Search**: TÃ¬m kiáº¿m theo source, section, doc_id
- **Hybrid Search**: Káº¿t há»£p semantic + metadata filtering

## ğŸ§ª Benchmarking System

### ğŸ“Š Hit@K Benchmark
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ kháº£ nÄƒng retrieval cá»§a embedding models

**Dataset**: BEIR ViHealthQA - ChuyÃªn biá»‡t cho domain y táº¿ tiáº¿ng Viá»‡t

**Metrics**:
- **Hit@1**: Accuracy á»Ÿ top-1 result
- **Hit@4**: Accuracy á»Ÿ top-4 results  
- **Hit@10**: Accuracy á»Ÿ top-10 results

### ğŸ“ˆ STS Correlation Benchmark
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a

**Dataset**: ViSTS (Vietnamese Semantic Textual Similarity)

**Metrics**:
- **Pearson Correlation**: TÆ°Æ¡ng quan tuyáº¿n tÃ­nh
- **Spearman Correlation**: TÆ°Æ¡ng quan thá»© háº¡ng

### ğŸ† Model Recommendations

| Model | Use Case | Performance | Speed |
|-------|----------|-------------|-------|
| `intfloat/multilingual-e5-base` | **Production** | â­â­â­â­ | ğŸš€ğŸš€ğŸš€ |
| `keepitreal/vietnamese-sbert` | **Vietnamese Specialized** | â­â­â­â­â­ | ğŸš€ğŸš€ |
| `Alibaba-NLP/gte-multilingual-base` | **High Accuracy** | â­â­â­â­â­ | ğŸš€ğŸš€ |
| `intfloat/multilingual-e5-large-instruct` | **Best Overall** | â­â­â­â­â­ | ğŸš€ |

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### ğŸ“¦ CÃ i Äáº·t Dependencies

```bash
cd src/data-preparing
pip install uv
uv sync
```

### ğŸ”„ Cháº¡y Data Ingestion

```bash
# PhÃ¢n tÃ­ch PDF (khÃ´ng lÆ°u vÃ o DB)
python ingest_data.py --analyze-only --data-dir ./data

# Xá»­ lÃ½ vÃ  lÆ°u vÃ o vector DB
python ingest_data.py --data-dir ./data

# Xá»­ lÃ½ vá»›i custom collection
python ingest_data.py --data-dir ./data --collection-name my_collection
```

### ğŸ§ª Cháº¡y Benchmarks

```bash
cd benchmarks/embedding

# Hit@K Benchmark
uv run hit_at_k_benchmark.py

# STS Correlation Benchmark  
uv run sts_correlation_benchmark.py
```

## ğŸ“Š Monitoring vÃ  Logging

### ğŸ“ˆ Processing Stats
```python
{
    "total_chunks": 1250,
    "total_characters": 2500000,
    "sections": {
        "ChÆ°Æ¡ng 1": 45,
        "ChÆ°Æ¡ng 2": 38,
        # ...
    },
    "sources": ["file1.pdf", "file2.pdf"],
    "doc_ids": ["uuid1", "uuid2"]
}
```

### ğŸ” Health Checks
- **Qdrant Connection**: Kiá»ƒm tra káº¿t ná»‘i vector DB
- **Embedding Model**: Validate model loading
- **Collection Status**: Kiá»ƒm tra collection vÃ  index

## ğŸ› ï¸ Troubleshooting

### âŒ Lá»—i ThÆ°á»ng Gáº·p

1. **"index out of range in self"**
   - **NguyÃªn nhÃ¢n**: Text quÃ¡ dÃ i hoáº·c cÃ³ kÃ½ tá»± Ä‘áº·c biá»‡t
   - **Giáº£i phÃ¡p**: Text preprocessing vÃ  batch size reduction

2. **"trust_remote_code=True required"**
   - **NguyÃªn nhÃ¢n**: Model yÃªu cáº§u trust remote code
   - **Giáº£i phÃ¡p**: Auto-retry vá»›i trust_remote_code=True

3. **Qdrant Connection Failed**
   - **NguyÃªn nhÃ¢n**: Qdrant server chÆ°a khá»Ÿi Ä‘á»™ng
   - **Giáº£i phÃ¡p**: `docker run -p 6333:6333 qdrant/qdrant`

### ğŸ”§ Performance Tuning

1. **TÄƒng tá»‘c Embedding**:
   - Giáº£m `EMBEDDING_BATCH_SIZE` náº¿u gáº·p OOM
   - Sá»­ dá»¥ng GPU náº¿u cÃ³ sáºµn
   - Chá»n model nhá» hÆ¡n cho production

2. **Tá»‘i Æ°u Chunking**:
   - Äiá»u chá»‰nh `CHUNK_SIZE` theo domain
   - TÄƒng `CHUNK_OVERLAP` Ä‘á»ƒ báº£o toÃ n context
   - Sá»­ dá»¥ng separators phÃ¹ há»£p vá»›i tiáº¿ng Viá»‡t

3. **Vector DB Performance**:
   - TÄƒng `TOP_K_DOCUMENTS` cho recall cao hÆ¡n
   - Äiá»u chá»‰nh `SIMILARITY_THRESHOLD` theo use case
   - Sá»­ dá»¥ng filtered search khi cÃ³ thá»ƒ

## ğŸ”® Roadmap

- [ ] **Multi-modal Support**: Xá»­ lÃ½ hÃ¬nh áº£nh trong PDF
- [ ] **Advanced Chunking**: Semantic chunking vá»›i LLM
- [ ] **Real-time Updates**: Incremental data ingestion
- [ ] **Quality Metrics**: Tá»± Ä‘á»™ng Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng chunks
- [ ] **A/B Testing**: So sÃ¡nh performance cÃ¡c embedding models

---

## ğŸ“ LiÃªn Há»‡ Há»— Trá»£

Náº¿u gáº·p váº¥n Ä‘á» khi sá»­ dá»¥ng há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u, vui lÃ²ng:

1. Kiá»ƒm tra logs chi tiáº¿t
2. Xem pháº§n Troubleshooting
3. Cháº¡y health checks
4. LiÃªn há»‡ team phÃ¡t triá»ƒn vá»›i thÃ´ng tin lá»—i cá»¥ thá»ƒ

**ğŸ¯ Há»‡ thá»‘ng Data Preparing Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ robust, scalable vÃ  tá»‘i Æ°u cho domain tÆ° váº¥n sá»©c khá»e tÃ¢m lÃ½ tiáº¿ng Viá»‡t!**
